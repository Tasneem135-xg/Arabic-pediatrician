{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of spacy_vaccine.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XFWwHTcGDl5f",
        "JkFN4gMUn7Vy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPAYPeqwn3o8"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtX0fIN9xzsJ"
      },
      "source": [
        "TRAIN_DATA="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIC4UEXfx2Ns"
      },
      "source": [
        "TEST="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkFN4gMUn7Vy"
      },
      "source": [
        "#code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veuBCRw8nrgM"
      },
      "source": [
        "# Load pre-existing spacy model\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"lemmatizer\"])\n",
        "# Getting the pipeline component\n",
        "ner=nlp.get_pipe(\"ner\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quSnA5WKoZGt"
      },
      "source": [
        "# Adding labels to the `ner`\n",
        "for _, annotations in TRAIN_DATA:\n",
        "  for ent in annotations.get(\"entities\"):\n",
        "    ner.add_label(ent[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGqEUPpcogCK"
      },
      "source": [
        "# Disable pipeline components you dont need to change\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw5HJUakoior",
        "outputId": "7c27ca58-d623-4fb4-a84a-da3fb44d0a25"
      },
      "source": [
        "# Import requirements\n",
        "import random\n",
        "from spacy.util import minibatch, compounding\n",
        "from pathlib import Path\n",
        "\n",
        "# TRAINING THE MODEL\n",
        "with nlp.disable_pipes(*unaffected_pipes):\n",
        "\n",
        "  # Training for 30 iterations\n",
        "  for iteration in range(30):\n",
        "\n",
        "    # shuufling examples  before every iteration\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    losses = {}\n",
        "    # batch up the examples using spaCy's minibatch\n",
        "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
        "    for batch in batches:\n",
        "        texts, annotations = zip(*batch)\n",
        "        nlp.update(\n",
        "                    texts,  # batch of texts\n",
        "                    annotations,  # batch of annotations\n",
        "                    drop=0.5,  # dropout - make it harder to memorise data\n",
        "                    losses=losses,\n",
        "                )\n",
        "        print(\"Losses\", losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 130.37268435955048}\n",
            "Losses {'ner': 236.8420752286911}\n",
            "Losses {'ner': 352.0752590894699}\n",
            "Losses {'ner': 487.73580634593964}\n",
            "Losses {'ner': 599.8777669668198}\n",
            "Losses {'ner': 758.275307059288}\n",
            "Losses {'ner': 902.6932066679001}\n",
            "Losses {'ner': 988.472078204155}\n",
            "Losses {'ner': 1139.740310549736}\n",
            "Losses {'ner': 1274.196305155754}\n",
            "Losses {'ner': 1413.106230378151}\n",
            "Losses {'ner': 1539.2843886613846}\n",
            "Losses {'ner': 1616.3227492570877}\n",
            "Losses {'ner': 1767.5088058710098}\n",
            "Losses {'ner': 1832.5191849470139}\n",
            "Losses {'ner': 92.86623287200928}\n",
            "Losses {'ner': 210.79034042358398}\n",
            "Losses {'ner': 326.3977847099304}\n",
            "Losses {'ner': 435.1685049533844}\n",
            "Losses {'ner': 559.2632358074188}\n",
            "Losses {'ner': 690.857507944107}\n",
            "Losses {'ner': 801.8003146648407}\n",
            "Losses {'ner': 919.8414151668549}\n",
            "Losses {'ner': 1054.2494633197784}\n",
            "Losses {'ner': 1121.3151636123657}\n",
            "Losses {'ner': 1187.0285668373108}\n",
            "Losses {'ner': 1316.6431965827942}\n",
            "Losses {'ner': 1402.4291043281555}\n",
            "Losses {'ner': 1515.9223880767822}\n",
            "Losses {'ner': 1590.1911211013794}\n",
            "Losses {'ner': 109.70510864257812}\n",
            "Losses {'ner': 181.54063749313354}\n",
            "Losses {'ner': 281.744264125824}\n",
            "Losses {'ner': 401.9572100639343}\n",
            "Losses {'ner': 509.934289932251}\n",
            "Losses {'ner': 585.3073291778564}\n",
            "Losses {'ner': 664.7436428070068}\n",
            "Losses {'ner': 743.0067672729492}\n",
            "Losses {'ner': 844.9639797210693}\n",
            "Losses {'ner': 964.7837343215942}\n",
            "Losses {'ner': 1020.7647271156311}\n",
            "Losses {'ner': 1089.2215297222137}\n",
            "Losses {'ner': 1169.2165098190308}\n",
            "Losses {'ner': 1253.4941968917847}\n",
            "Losses {'ner': 1336.9254367351532}\n",
            "Losses {'ner': 62.77941536903381}\n",
            "Losses {'ner': 121.93031811714172}\n",
            "Losses {'ner': 171.499365568161}\n",
            "Losses {'ner': 282.4245479106903}\n",
            "Losses {'ner': 395.5995559692383}\n",
            "Losses {'ner': 478.12920665740967}\n",
            "Losses {'ner': 597.818699836731}\n",
            "Losses {'ner': 695.7510070800781}\n",
            "Losses {'ner': 802.3774409294128}\n",
            "Losses {'ner': 898.4745903015137}\n",
            "Losses {'ner': 971.5674557685852}\n",
            "Losses {'ner': 1053.8984167575836}\n",
            "Losses {'ner': 1145.8883094787598}\n",
            "Losses {'ner': 1237.831114768982}\n",
            "Losses {'ner': 1294.7045850753784}\n",
            "Losses {'ner': 74.73567962646484}\n",
            "Losses {'ner': 145.11655449867249}\n",
            "Losses {'ner': 237.92362546920776}\n",
            "Losses {'ner': 352.501916885376}\n",
            "Losses {'ner': 424.6339325904846}\n",
            "Losses {'ner': 521.0538754463196}\n",
            "Losses {'ner': 607.273374080658}\n",
            "Losses {'ner': 687.3340077400208}\n",
            "Losses {'ner': 801.4160676002502}\n",
            "Losses {'ner': 865.4553608894348}\n",
            "Losses {'ner': 930.6090598106384}\n",
            "Losses {'ner': 1041.290014743805}\n",
            "Losses {'ner': 1125.5350546836853}\n",
            "Losses {'ner': 1210.2326719760895}\n",
            "Losses {'ner': 1277.6051440238953}\n",
            "Losses {'ner': 91.32668590545654}\n",
            "Losses {'ner': 159.15006256103516}\n",
            "Losses {'ner': 260.621365070343}\n",
            "Losses {'ner': 327.63609313964844}\n",
            "Losses {'ner': 407.3407657146454}\n",
            "Losses {'ner': 498.5344033241272}\n",
            "Losses {'ner': 591.0147728919983}\n",
            "Losses {'ner': 695.4116377830505}\n",
            "Losses {'ner': 765.635251045227}\n",
            "Losses {'ner': 838.3015294075012}\n",
            "Losses {'ner': 926.568069934845}\n",
            "Losses {'ner': 993.4694995880127}\n",
            "Losses {'ner': 1092.200792312622}\n",
            "Losses {'ner': 1196.2042760849}\n",
            "Losses {'ner': 1260.5218189954758}\n",
            "Losses {'ner': 78.01629972457886}\n",
            "Losses {'ner': 182.11223340034485}\n",
            "Losses {'ner': 276.2765986919403}\n",
            "Losses {'ner': 353.8579742908478}\n",
            "Losses {'ner': 435.08570981025696}\n",
            "Losses {'ner': 522.4637463092804}\n",
            "Losses {'ner': 605.6299459934235}\n",
            "Losses {'ner': 694.5478627681732}\n",
            "Losses {'ner': 787.1699345111847}\n",
            "Losses {'ner': 861.9165589809418}\n",
            "Losses {'ner': 945.0051915645599}\n",
            "Losses {'ner': 1018.2716839313507}\n",
            "Losses {'ner': 1100.0367901325226}\n",
            "Losses {'ner': 1162.477380990982}\n",
            "Losses {'ner': 1264.0707912445068}\n",
            "Losses {'ner': 76.8160810470581}\n",
            "Losses {'ner': 153.5608925819397}\n",
            "Losses {'ner': 223.74141120910645}\n",
            "Losses {'ner': 327.5581376552582}\n",
            "Losses {'ner': 422.0597765445709}\n",
            "Losses {'ner': 502.9462068080902}\n",
            "Losses {'ner': 578.2577750682831}\n",
            "Losses {'ner': 671.1203062534332}\n",
            "Losses {'ner': 753.3602600097656}\n",
            "Losses {'ner': 846.8185663223267}\n",
            "Losses {'ner': 946.7900066375732}\n",
            "Losses {'ner': 1016.3053035736084}\n",
            "Losses {'ner': 1102.775556087494}\n",
            "Losses {'ner': 1183.9781403541565}\n",
            "Losses {'ner': 1265.387839436531}\n",
            "Losses {'ner': 96.08498954772949}\n",
            "Losses {'ner': 163.86361265182495}\n",
            "Losses {'ner': 287.70433163642883}\n",
            "Losses {'ner': 362.4482822418213}\n",
            "Losses {'ner': 469.00907373428345}\n",
            "Losses {'ner': 560.794960975647}\n",
            "Losses {'ner': 650.1177043914795}\n",
            "Losses {'ner': 727.7680993080139}\n",
            "Losses {'ner': 829.2637767791748}\n",
            "Losses {'ner': 896.9054441452026}\n",
            "Losses {'ner': 976.9315342903137}\n",
            "Losses {'ner': 1046.974464416504}\n",
            "Losses {'ner': 1112.5971584320068}\n",
            "Losses {'ner': 1200.4780707359314}\n",
            "Losses {'ner': 1258.4285912513733}\n",
            "Losses {'ner': 55.771892070770264}\n",
            "Losses {'ner': 157.65785241127014}\n",
            "Losses {'ner': 267.81344294548035}\n",
            "Losses {'ner': 367.5686843395233}\n",
            "Losses {'ner': 457.3374283313751}\n",
            "Losses {'ner': 528.7911560535431}\n",
            "Losses {'ner': 618.2315180301666}\n",
            "Losses {'ner': 693.4059164524078}\n",
            "Losses {'ner': 745.0508654117584}\n",
            "Losses {'ner': 825.4111926555634}\n",
            "Losses {'ner': 916.9070718288422}\n",
            "Losses {'ner': 1030.5303237438202}\n",
            "Losses {'ner': 1113.1598074436188}\n",
            "Losses {'ner': 1215.8326890468597}\n",
            "Losses {'ner': 1262.6931240558624}\n",
            "Losses {'ner': 88.45498752593994}\n",
            "Losses {'ner': 197.65356993675232}\n",
            "Losses {'ner': 286.20019125938416}\n",
            "Losses {'ner': 364.64522981643677}\n",
            "Losses {'ner': 447.2206039428711}\n",
            "Losses {'ner': 524.7246446609497}\n",
            "Losses {'ner': 627.155282497406}\n",
            "Losses {'ner': 713.1823606491089}\n",
            "Losses {'ner': 798.4327354431152}\n",
            "Losses {'ner': 865.3712787628174}\n",
            "Losses {'ner': 946.3705940246582}\n",
            "Losses {'ner': 1027.1734554767609}\n",
            "Losses {'ner': 1103.5756385326385}\n",
            "Losses {'ner': 1190.735596895218}\n",
            "Losses {'ner': 1259.5058195590973}\n",
            "Losses {'ner': 110.20556640625}\n",
            "Losses {'ner': 178.8332324028015}\n",
            "Losses {'ner': 243.6773419380188}\n",
            "Losses {'ner': 329.937961101532}\n",
            "Losses {'ner': 438.1638045310974}\n",
            "Losses {'ner': 496.2945489883423}\n",
            "Losses {'ner': 570.260251045227}\n",
            "Losses {'ner': 663.3506994247437}\n",
            "Losses {'ner': 748.0411841869354}\n",
            "Losses {'ner': 831.7620589733124}\n",
            "Losses {'ner': 910.9092395305634}\n",
            "Losses {'ner': 993.7730929851532}\n",
            "Losses {'ner': 1108.0264055728912}\n",
            "Losses {'ner': 1178.7357857227325}\n",
            "Losses {'ner': 1249.5094470977783}\n",
            "Losses {'ner': 81.56405639648438}\n",
            "Losses {'ner': 143.25132989883423}\n",
            "Losses {'ner': 240.153005361557}\n",
            "Losses {'ner': 332.30474615097046}\n",
            "Losses {'ner': 407.6884150505066}\n",
            "Losses {'ner': 497.8180570602417}\n",
            "Losses {'ner': 593.7316646575928}\n",
            "Losses {'ner': 667.3751173019409}\n",
            "Losses {'ner': 752.4647426605225}\n",
            "Losses {'ner': 860.5659801959991}\n",
            "Losses {'ner': 950.54505610466}\n",
            "Losses {'ner': 1018.357362985611}\n",
            "Losses {'ner': 1116.4389889240265}\n",
            "Losses {'ner': 1199.8459823131561}\n",
            "Losses {'ner': 1263.107326745987}\n",
            "Losses {'ner': 75.57380056381226}\n",
            "Losses {'ner': 157.18556928634644}\n",
            "Losses {'ner': 227.7855954170227}\n",
            "Losses {'ner': 328.759779214859}\n",
            "Losses {'ner': 425.810298204422}\n",
            "Losses {'ner': 524.3994195461273}\n",
            "Losses {'ner': 600.5782725811005}\n",
            "Losses {'ner': 681.321727514267}\n",
            "Losses {'ner': 754.5758326053619}\n",
            "Losses {'ner': 865.06569647789}\n",
            "Losses {'ner': 938.7063853740692}\n",
            "Losses {'ner': 1044.688297510147}\n",
            "Losses {'ner': 1108.4397718906403}\n",
            "Losses {'ner': 1186.9318706989288}\n",
            "Losses {'ner': 1252.869193315506}\n",
            "Losses {'ner': 75.06437110900879}\n",
            "Losses {'ner': 141.3002941608429}\n",
            "Losses {'ner': 209.9370472431183}\n",
            "Losses {'ner': 285.65262746810913}\n",
            "Losses {'ner': 379.24311542510986}\n",
            "Losses {'ner': 482.2134885787964}\n",
            "Losses {'ner': 612.1856215000153}\n",
            "Losses {'ner': 699.7034022808075}\n",
            "Losses {'ner': 784.1911404132843}\n",
            "Losses {'ner': 875.1471128463745}\n",
            "Losses {'ner': 948.1611542701721}\n",
            "Losses {'ner': 1024.2915122509003}\n",
            "Losses {'ner': 1106.8598773479462}\n",
            "Losses {'ner': 1176.1513721942902}\n",
            "Losses {'ner': 1258.6605461835861}\n",
            "Losses {'ner': 77.49161338806152}\n",
            "Losses {'ner': 129.44954204559326}\n",
            "Losses {'ner': 221.66429662704468}\n",
            "Losses {'ner': 308.9992847442627}\n",
            "Losses {'ner': 429.2036442756653}\n",
            "Losses {'ner': 531.8060455322266}\n",
            "Losses {'ner': 611.2070817947388}\n",
            "Losses {'ner': 717.991613149643}\n",
            "Losses {'ner': 812.3469223976135}\n",
            "Losses {'ner': 889.8202185630798}\n",
            "Losses {'ner': 954.1530380249023}\n",
            "Losses {'ner': 1036.9285650253296}\n",
            "Losses {'ner': 1128.4908227920532}\n",
            "Losses {'ner': 1187.3955199718475}\n",
            "Losses {'ner': 1251.782318353653}\n",
            "Losses {'ner': 67.40384912490845}\n",
            "Losses {'ner': 185.9500846862793}\n",
            "Losses {'ner': 283.7623338699341}\n",
            "Losses {'ner': 384.93599128723145}\n",
            "Losses {'ner': 476.04690647125244}\n",
            "Losses {'ner': 545.044355392456}\n",
            "Losses {'ner': 634.9068703651428}\n",
            "Losses {'ner': 698.1566851139069}\n",
            "Losses {'ner': 775.0118906497955}\n",
            "Losses {'ner': 855.5512435436249}\n",
            "Losses {'ner': 935.5845677852631}\n",
            "Losses {'ner': 1021.6035249233246}\n",
            "Losses {'ner': 1107.4395463466644}\n",
            "Losses {'ner': 1168.5689074993134}\n",
            "Losses {'ner': 1249.037185907364}\n",
            "Losses {'ner': 83.82873225212097}\n",
            "Losses {'ner': 161.4254114627838}\n",
            "Losses {'ner': 233.98888325691223}\n",
            "Losses {'ner': 325.2465908527374}\n",
            "Losses {'ner': 413.5433645248413}\n",
            "Losses {'ner': 526.9604892730713}\n",
            "Losses {'ner': 582.0941996574402}\n",
            "Losses {'ner': 704.8929476737976}\n",
            "Losses {'ner': 788.5714383125305}\n",
            "Losses {'ner': 899.8585486412048}\n",
            "Losses {'ner': 978.7831425666809}\n",
            "Losses {'ner': 1031.543697834015}\n",
            "Losses {'ner': 1106.3356230258942}\n",
            "Losses {'ner': 1182.9017007350922}\n",
            "Losses {'ner': 1241.4944007396698}\n",
            "Losses {'ner': 82.88478374481201}\n",
            "Losses {'ner': 137.87134265899658}\n",
            "Losses {'ner': 240.20570611953735}\n",
            "Losses {'ner': 326.6035866737366}\n",
            "Losses {'ner': 458.3260943889618}\n",
            "Losses {'ner': 539.4950368404388}\n",
            "Losses {'ner': 634.1868164539337}\n",
            "Losses {'ner': 710.3606581687927}\n",
            "Losses {'ner': 809.7950267791748}\n",
            "Losses {'ner': 893.1828410625458}\n",
            "Losses {'ner': 966.0101294517517}\n",
            "Losses {'ner': 1049.2323365211487}\n",
            "Losses {'ner': 1129.0552020072937}\n",
            "Losses {'ner': 1198.4065446853638}\n",
            "Losses {'ner': 1255.3397986888885}\n",
            "Losses {'ner': 82.84353923797607}\n",
            "Losses {'ner': 155.53658246994019}\n",
            "Losses {'ner': 253.9950122833252}\n",
            "Losses {'ner': 350.60229206085205}\n",
            "Losses {'ner': 456.04352045059204}\n",
            "Losses {'ner': 529.9025025367737}\n",
            "Losses {'ner': 605.3549098968506}\n",
            "Losses {'ner': 671.6332583427429}\n",
            "Losses {'ner': 759.3698797225952}\n",
            "Losses {'ner': 846.4593896865845}\n",
            "Losses {'ner': 941.6517806053162}\n",
            "Losses {'ner': 1007.2988259792328}\n",
            "Losses {'ner': 1098.747942686081}\n",
            "Losses {'ner': 1189.3084936141968}\n",
            "Losses {'ner': 1241.4192214012146}\n",
            "Losses {'ner': 108.09435701370239}\n",
            "Losses {'ner': 203.1037039756775}\n",
            "Losses {'ner': 264.6885290145874}\n",
            "Losses {'ner': 326.8042526245117}\n",
            "Losses {'ner': 402.80112862586975}\n",
            "Losses {'ner': 488.43881916999817}\n",
            "Losses {'ner': 595.6370432376862}\n",
            "Losses {'ner': 668.840936422348}\n",
            "Losses {'ner': 757.6150743961334}\n",
            "Losses {'ner': 840.8633649349213}\n",
            "Losses {'ner': 924.1788349151611}\n",
            "Losses {'ner': 1012.3078765869141}\n",
            "Losses {'ner': 1082.9552021026611}\n",
            "Losses {'ner': 1167.8657631874084}\n",
            "Losses {'ner': 1240.6642289161682}\n",
            "Losses {'ner': 79.70233464241028}\n",
            "Losses {'ner': 151.69420266151428}\n",
            "Losses {'ner': 234.85883903503418}\n",
            "Losses {'ner': 321.9772825241089}\n",
            "Losses {'ner': 403.660760641098}\n",
            "Losses {'ner': 462.2770709991455}\n",
            "Losses {'ner': 555.3236994743347}\n",
            "Losses {'ner': 638.4714217185974}\n",
            "Losses {'ner': 746.0737941265106}\n",
            "Losses {'ner': 822.4530031681061}\n",
            "Losses {'ner': 920.2908020019531}\n",
            "Losses {'ner': 1004.136239528656}\n",
            "Losses {'ner': 1088.8426096439362}\n",
            "Losses {'ner': 1166.5449397563934}\n",
            "Losses {'ner': 1233.8813812732697}\n",
            "Losses {'ner': 82.5984582901001}\n",
            "Losses {'ner': 175.11699533462524}\n",
            "Losses {'ner': 255.87018465995789}\n",
            "Losses {'ner': 319.607905626297}\n",
            "Losses {'ner': 392.9471957683563}\n",
            "Losses {'ner': 499.3042404651642}\n",
            "Losses {'ner': 567.6097948551178}\n",
            "Losses {'ner': 676.0923311710358}\n",
            "Losses {'ner': 777.1201012134552}\n",
            "Losses {'ner': 857.209555387497}\n",
            "Losses {'ner': 924.4394872188568}\n",
            "Losses {'ner': 1021.7976725101471}\n",
            "Losses {'ner': 1108.3054745197296}\n",
            "Losses {'ner': 1176.7077996730804}\n",
            "Losses {'ner': 1234.6640031337738}\n",
            "Losses {'ner': 97.85696506500244}\n",
            "Losses {'ner': 161.15987634658813}\n",
            "Losses {'ner': 251.70265769958496}\n",
            "Losses {'ner': 340.31399869918823}\n",
            "Losses {'ner': 422.1844263076782}\n",
            "Losses {'ner': 514.3876128196716}\n",
            "Losses {'ner': 628.5636112689972}\n",
            "Losses {'ner': 723.4071609973907}\n",
            "Losses {'ner': 808.4433476924896}\n",
            "Losses {'ner': 867.6957561969757}\n",
            "Losses {'ner': 969.5126292705536}\n",
            "Losses {'ner': 1031.2153432369232}\n",
            "Losses {'ner': 1103.9535887241364}\n",
            "Losses {'ner': 1185.6078040599823}\n",
            "Losses {'ner': 1220.989090681076}\n",
            "Losses {'ner': 100.05037307739258}\n",
            "Losses {'ner': 167.9351351261139}\n",
            "Losses {'ner': 236.8792073726654}\n",
            "Losses {'ner': 346.81852889060974}\n",
            "Losses {'ner': 442.65465331077576}\n",
            "Losses {'ner': 528.8515503406525}\n",
            "Losses {'ner': 594.297874212265}\n",
            "Losses {'ner': 676.2464053630829}\n",
            "Losses {'ner': 780.2207634449005}\n",
            "Losses {'ner': 867.2305068969727}\n",
            "Losses {'ner': 908.5130982398987}\n",
            "Losses {'ner': 991.4986140727997}\n",
            "Losses {'ner': 1090.3370842933655}\n",
            "Losses {'ner': 1184.6747884750366}\n",
            "Losses {'ner': 1234.7086281776428}\n",
            "Losses {'ner': 105.96384477615356}\n",
            "Losses {'ner': 224.14285564422607}\n",
            "Losses {'ner': 297.93470573425293}\n",
            "Losses {'ner': 366.45787620544434}\n",
            "Losses {'ner': 430.90051889419556}\n",
            "Losses {'ner': 513.9461805820465}\n",
            "Losses {'ner': 635.2859966754913}\n",
            "Losses {'ner': 727.7645547389984}\n",
            "Losses {'ner': 779.6382982730865}\n",
            "Losses {'ner': 860.5078015327454}\n",
            "Losses {'ner': 929.8728566169739}\n",
            "Losses {'ner': 1002.0725717544556}\n",
            "Losses {'ner': 1063.1368436813354}\n",
            "Losses {'ner': 1151.6472024917603}\n",
            "Losses {'ner': 1232.811882019043}\n",
            "Losses {'ner': 80.48492479324341}\n",
            "Losses {'ner': 152.53340005874634}\n",
            "Losses {'ner': 240.8223156929016}\n",
            "Losses {'ner': 309.49978017807007}\n",
            "Losses {'ner': 380.4934787750244}\n",
            "Losses {'ner': 504.84862422943115}\n",
            "Losses {'ner': 582.2583246231079}\n",
            "Losses {'ner': 671.3469083309174}\n",
            "Losses {'ner': 750.9336364269257}\n",
            "Losses {'ner': 829.1582524776459}\n",
            "Losses {'ner': 912.8728475570679}\n",
            "Losses {'ner': 977.6224851608276}\n",
            "Losses {'ner': 1057.0622668266296}\n",
            "Losses {'ner': 1165.4229612350464}\n",
            "Losses {'ner': 1224.6340684890747}\n",
            "Losses {'ner': 96.59416484832764}\n",
            "Losses {'ner': 199.7068088054657}\n",
            "Losses {'ner': 254.9463746547699}\n",
            "Losses {'ner': 364.70702719688416}\n",
            "Losses {'ner': 451.5159811973572}\n",
            "Losses {'ner': 550.3020243644714}\n",
            "Losses {'ner': 654.9079313278198}\n",
            "Losses {'ner': 724.5523881912231}\n",
            "Losses {'ner': 791.9977469444275}\n",
            "Losses {'ner': 867.9906949996948}\n",
            "Losses {'ner': 928.1585621833801}\n",
            "Losses {'ner': 1004.9092302322388}\n",
            "Losses {'ner': 1073.9161367416382}\n",
            "Losses {'ner': 1148.588069677353}\n",
            "Losses {'ner': 1208.5546543598175}\n",
            "Losses {'ner': 66.13344240188599}\n",
            "Losses {'ner': 130.69909763336182}\n",
            "Losses {'ner': 206.2865228652954}\n",
            "Losses {'ner': 297.72856998443604}\n",
            "Losses {'ner': 389.59104585647583}\n",
            "Losses {'ner': 490.57063484191895}\n",
            "Losses {'ner': 574.8493123054504}\n",
            "Losses {'ner': 645.2645261287689}\n",
            "Losses {'ner': 729.447984457016}\n",
            "Losses {'ner': 839.5367815494537}\n",
            "Losses {'ner': 911.4228668212891}\n",
            "Losses {'ner': 963.0297107696533}\n",
            "Losses {'ner': 1059.6531729698181}\n",
            "Losses {'ner': 1153.1853969097137}\n",
            "Losses {'ner': 1221.0883247852325}\n",
            "Losses {'ner': 97.02046465873718}\n",
            "Losses {'ner': 156.84677863121033}\n",
            "Losses {'ner': 244.83222818374634}\n",
            "Losses {'ner': 311.8616409301758}\n",
            "Losses {'ner': 392.7642273902893}\n",
            "Losses {'ner': 487.3851158618927}\n",
            "Losses {'ner': 575.996417760849}\n",
            "Losses {'ner': 644.1935586929321}\n",
            "Losses {'ner': 718.4167094230652}\n",
            "Losses {'ner': 804.9357504844666}\n",
            "Losses {'ner': 913.7067422866821}\n",
            "Losses {'ner': 1013.5788459777832}\n",
            "Losses {'ner': 1109.9767398834229}\n",
            "Losses {'ner': 1157.8270027637482}\n",
            "Losses {'ner': 1219.59894490242}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3RGV3iE7G9w",
        "outputId": "0f8107fd-7891-4e08-dd33-75592cf8b425"
      },
      "source": [
        "# Testing the model\n",
        "doc = nlp('اريد ان اعرف اذا لم ياخذ الطفل جرعة من جرعات تطعيم شلل الاطفال الفموي يقدم التطعيم الفموي على عدة مراحل عمرية يسبب له مشاكل او اية اعراض')\n",
        "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entities [('من', 'GR'), ('تطعيم', 'IV'), ('التطعيم', 'IV'), ('على', 'GR'), ('مراحل', 'N'), ('عمرية', 'N'), ('اعراض', 'N')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceSA0V9p6Z9Q"
      },
      "source": [
        "#test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYcHPEb85_tM"
      },
      "source": [
        "def report_scores(scores, e):\n",
        "    \"\"\"\n",
        "    prints precision recall and f_measure\n",
        "    :param scores:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    precision = '%.2f' % scores['ents_p']\n",
        "    recall = '%.2f' % scores['ents_r']\n",
        "    f_measure = '%.2f' % scores['ents_f']\n",
        "    print('%-25s %-10s %-10s %-10s' % (e, precision, recall, f_measure))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWYu0m5A9f9C",
        "outputId": "700fa021-e8b1-4a9c-861d-18f75efd7230"
      },
      "source": [
        "import spacy\n",
        "from spacy.gold import GoldParse\n",
        "from spacy.scorer import Scorer\n",
        "\n",
        "def evaluate(nlp, examples, ent= ['VAC','M','IM','IV','LEN','IS','D','ID','IAG','T','IP','P','AG','S','DI','DO','F','DIS']):\n",
        "    scorer = Scorer()\n",
        "    for input_, annot in examples:\n",
        "        text_entities = []\n",
        "        for entity in annot.get('entities'):\n",
        "            if ent in entity:\n",
        "                text_entities.append(entity)\n",
        "        doc_gold_text = nlp.make_doc(input_)\n",
        "        gold = GoldParse(doc_gold_text, entities=text_entities)\n",
        "        pred_value = nlp(input_)\n",
        "        scorer.score(pred_value, gold)\n",
        "    return scorer.scores\n",
        "\n",
        "\n",
        "examples = TRAIN_DATA\n",
        "\n",
        "#nlp = spacy.load('en_core_web_sm')\n",
        "results = evaluate(nlp, examples)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'uas': 0.0, 'las': 0.0, 'las_per_type': {'compound': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'nmod': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'amod': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'root': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'prep': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'pobj': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'nummod': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'dobj': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'advmod': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'nsubj': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'ccomp': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'acomp': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'npadvmod': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'aux': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'relcl': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'conj': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'xcomp': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'intj': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'appos': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'advcl': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'dative': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'attr': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'det': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'oprd': {'p': 0.0, 'r': 0.0, 'f': 0.0}}, 'ents_p': 0.0, 'ents_r': 0.0, 'ents_f': 0.0, 'ents_per_type': {'IV': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'GR': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'Q': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'V': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'N': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'AG': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'M': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'C': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'IAG': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'SH': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'G': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'NEG': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'VAC': {'p': 0.0, 'r': 0.0, 'f': 0.0}}, 'tags_acc': 0.0, 'token_acc': 100.0, 'textcat_score': 0.0, 'textcats_per_cat': {}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSjYrXrt-yL1",
        "outputId": "f57ed601-2fbc-419c-95d5-418a3b54f6ba"
      },
      "source": [
        "ents = ['VAC','M','IM','IV','LEN','IS','D','ID','IAG','T','IP','P','AG','S','DI','DO','F','DIS']\n",
        "print('%-25s %-10s %-10s %-10s' % (\"Entity\", \"Precision\", \"Recall\", \"f-measure\"))\n",
        "for e in ents:\n",
        "    results = evaluate(nlp, TEST, e)\n",
        "# calculate precision, recall, f_measure\n",
        "    report_scores(results, e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entity                    Precision  Recall     f-measure \n",
            "VAC                       0.00       0.00       0.00      \n",
            "M                         0.00       0.00       0.00      \n",
            "IM                        0.00       0.00       0.00      \n",
            "IV                        1.88       42.11      3.60      \n",
            "LEN                       0.00       0.00       0.00      \n",
            "IS                        0.00       0.00       0.00      \n",
            "D                         0.00       0.00       0.00      \n",
            "ID                        0.00       0.00       0.00      \n",
            "IAG                       0.47       22.22      0.92      \n",
            "T                         0.00       0.00       0.00      \n",
            "IP                        0.00       0.00       0.00      \n",
            "P                         0.00       0.00       0.00      \n",
            "AG                        0.94       28.57      1.82      \n",
            "S                         0.00       0.00       0.00      \n",
            "DI                        0.00       0.00       0.00      \n",
            "DO                        0.00       0.00       0.00      \n",
            "F                         0.00       0.00       0.00      \n",
            "DIS                       0.00       0.00       0.00      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Oo1lAHf55Am"
      },
      "source": [
        "#SAVING AND LOADING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Gg2CH34T-AH",
        "outputId": "8555db0c-91b4-4f97-ab87-f04a1f0b58e9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPn_rlIw7HK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a80632f4-e2a8-4e3d-d8e5-79392f5f382f"
      },
      "source": [
        "# Save the  model to directory\n",
        "#output_dir = Path('/content/')\n",
        "\n",
        "output_dir = Path('/content/gdrive/MyDrive/NER_BERT/')\n",
        "\n",
        "#/content/drive/MyDrive/NER_BERT\n",
        "\n",
        "nlp.to_disk(output_dir)\n",
        "print(\"Saved model to\", output_dir)\n",
        "\n",
        "# Load the saved model and predict\n",
        "print(\"Loading from\", output_dir)\n",
        "nlp_updated = spacy.load(output_dir)\n",
        "\n",
        "\n",
        "\n",
        "doc = nlp_updated(\"Fridge can be ordered in FlipKart\" )\n",
        "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to /content/gdrive/MyDrive/NER_BERT\n",
            "Loading from /content/gdrive/MyDrive/NER_BERT\n",
            "Entities [('ordered', 'V')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P-TRAnh7HRx"
      },
      "source": [
        "#nlp.to_disk('nlp_spacyy_model_drug')\n",
        "#####nlp_model = spacy.load('nlp_spacyy_model_drug')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UEYC7EHrChi"
      },
      "source": [
        "#doc=nlp_model(\"و قالبستي كلاااام\")\n",
        "#####print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGgfcMz7wPmB"
      },
      "source": [
        "#joblib.dump(value=sgd, filename='sgd_model.pkl', protocol=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwffXO8vwYFL"
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(nlp, open( \"nlp.p\", \"wb\" ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4YfubGbw0Ni"
      },
      "source": [
        "#file = open(\"nlp.p\",'r')\n",
        "#object_file = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxMB0Ub6xhZG"
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "# Serialize the pipeline\n",
        "joblib.dump(value=nlp, filename='spa22_model_vacc.pkl', protocol=2)\n",
        "\n",
        "new_model = joblib.load('spa22_model_vacc.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP1u3F0sxvF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54634bcc-7ab7-4920-9a8a-8733079a4635"
      },
      "source": [
        "doc=new_model(\"و قالبستي كلاااام\")\n",
        "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entities []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4ZmDDSf37vP"
      },
      "source": [
        "from spacy.lemmatizer import Lemmatizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFlmmvWv373l"
      },
      "source": [
        "spacyy= joblib.load('spa22_model_vacc.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU0mRLfz376m",
        "outputId": "07a901d6-7efd-4702-b54d-4d6609e92f03"
      },
      "source": [
        "doc=spacyy('اريد ان اعرف اذا لم ياخذ الطفل جرعة من جرعات تطعيم شلل الاطفال الفموي يقدم التطعيم الفموي على عدة مراحل عمرية يسبب له مشاكل او اية اعراض')\n",
        "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entities [('من', 'GR'), ('تطعيم', 'IV'), ('التطعيم', 'IV'), ('على', 'GR'), ('مراحل', 'N'), ('عمرية', 'N'), ('اعراض', 'N')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}